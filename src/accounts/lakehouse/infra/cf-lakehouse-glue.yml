AWSTemplateFormatVersion: 2010-09-09
Description: AWSCloudFormationStackSetAdministrationRole to enable use of AWS CloudFormation StackSets.

Parameters:
  ComponentID:
    Description: This templates' component identifier string
    Type: String
    Default: lh-glue
  Env:
    Description: The environment in which the account is being deployed.
    Type: String
    Default: dev
    AllowedValues:
      - dev
      - qa
      - prod


Resources:
  IngestionWorkflow:
    Type: AWS::Glue::Workflow
    Properties:
      Name: !Sub "${Env}-lakehouse-${ComponentID}-datalake-ingestion-workflow"
      Description: "Workflow to orchestrate data ingestion into the S3 data lake."

  GlueJobRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - glue.amazonaws.com
                - lakeformation.amazonaws.com
            Action: 'sts:AssumeRole'
      ManagedPolicyArns:
        - 'arn:aws:iam::aws:policy/service-role/AWSGlueServiceRole'
      Policies:
        - PolicyName: !Sub '${Env}-lakehouse-${ComponentID}-role-policy-1'
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              -
                Effect: "Allow"
                Action: 
                  - "s3:*"
                  - "glue:*"
                  - "logs:*"
                  - "lakeformation:*"
                Resource:
                  - !Join [ '', ["arn:aws:s3:::*"]]
                  - !Join [ '', ["arn:aws:glue:*:*:", "*"]]
                  - !Join [ '', ["arn:aws:lakeformation:*:*", "*"]]
                  - !Join [ '', ["arn:aws:logs:*:*:", "*"]]
    
  RawToTransformedJobTrigger:
    Type: AWS::Glue::Trigger
    Properties:
      Name: !Sub "${Env}-lakehouse-${ComponentID}-data-clean-job-trigger"
      WorkflowName: !Ref IngestionWorkflow
      Type: "ON_DEMAND"
      Description: "Triggers the data lake ingestion workflow."
      Actions:
        - JobName: !Ref RawToTransformedJob
          Arguments:
            "--job-bookmark-option": "job-bookmark-enable"

  RawToTransformedJob:
    Type: AWS::Glue::Job
    Properties:
      Name: !Sub "${Env}-lakehouse-${ComponentID}-data-prep-job"
      Description: "Cleans raw data into the transformed bucket in prep for curation."
      MaxRetries: 3
      Role: !Ref GlueJobRole
      Command:
        Name: glueetl
        PythonVersion: "3"
        ScriptLocation: !Join ['', ["s3://", !ImportValue "LH:GlueJobScriptBucketName",  "/scripts_lh/clean-data.py"]]
      GlueVersion: "1.0"
      ExecutionProperty:
        MaxConcurrentRuns: 2
      WorkerType: Standard
      NumberOfWorkers: 2
      DefaultArguments:  
        "--LOG_LEVEL": "INFO"
        "--enable-continuous-cloudwatch-log": true
        "--enable-continuous-log-filter": true
        "--enable-s3-parquet-optimized-committer": true
        "--enable-metrics": ""
        "--encryption-type": sse-s3
        "--job-bookmark-option": job-bookmark-enable
        # "--TempDir": !Sub s3://aws-glue-temporary-${AWS::AccountId}-${AWS::Region}/admin

  TransformedToCuratedJobTrigger:
    Type: AWS::Glue::Trigger
    Properties:
      Name: !Sub "${Env}-lakehouse-${ComponentID}-data-curate-job-trigger"
      WorkflowName: !Ref IngestionWorkflow
      Type: "CONDITIONAL"
      StartOnCreation: true
      Description: "Initiates curation job under the condition that the data cleaning job runs successfully."
      Actions:
        - JobName: !Ref TransformedToCuratedJob
          Arguments:
            "--job-bookmark-option": "job-bookmark-enable"
      Predicate:
        Conditions:
          - LogicalOperator: EQUALS
            JobName: !Ref RawToTransformedJob
            State: SUCCEEDED

  TransformedToCuratedJob:
    Type: AWS::Glue::Job
    Properties:
      Name: !Sub "${Env}-lakehouse-${ComponentID}-data-curate-job"
      Description: "Curates cleaned data into the target data lake bucket."
      MaxRetries: 3
      Role: !Ref GlueJobRole
      Command:
        Name: glueetl
        PythonVersion: "3"
        ScriptLocation: !Join ['', ["s3://", !ImportValue "LH:GlueJobScriptBucketName",  "/scripts_lh/curate-data.py"]]
      GlueVersion: "1.0"
      ExecutionProperty:
        MaxConcurrentRuns: 2
      WorkerType: Standard
      NumberOfWorkers: 2
      DefaultArguments:  
        "--LOG_LEVEL": "INFO"
        "--enable-continuous-cloudwatch-log": true
        "--enable-continuous-log-filter": true
        "--enable-s3-parquet-optimized-committer": true
        "--enable-metrics": ""
        "--encryption-type": sse-s3
        "--job-bookmark-option": job-bookmark-enable

