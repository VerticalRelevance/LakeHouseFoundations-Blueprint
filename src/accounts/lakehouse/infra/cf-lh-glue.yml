AWSTemplateFormatVersion: 2010-09-09
Description: Lake House Account Glue Resources

Parameters:
  DeploymentRootName:
    Description: Root name of project/component deployment
    Type: String
    Default: lakehouse
  AccountShorthand:
    Description: Abbreviated logical account identifier
    Type: String
    Default: lh
  CompId:
    Description: This templates' component identifier string
    Type: String
    Default: lh-glue
  Env:
    Description: The environment in which the account is being deployed.
    Type: String
    Default: dev
    AllowedValues:
      - dev
      - qa
      - prod
  Region:
    Description: The region for the template to be deployed.
    Type: String
    Default: us-east-2
    AllowedValues:
      - us-east-2
      - us-east-1

Resources:
  IngestionWorkflow:
    Type: AWS::Glue::Workflow
    Properties:
      Name: !Sub "${Env}-${DeploymentRootName}-${CompId}-datalake-ingestion-workflow-${AWS::AccountId}-${Region}"
      Description: "Workflow to orchestrate data ingestion into the S3 data lake."
  GlueJobRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub "${Env}-${DeploymentRootName}-${CompId}-role-${AWS::AccountId}-${Region}"
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - glue.amazonaws.com
                - lakeformation.amazonaws.com
            Action: 'sts:AssumeRole'
      ManagedPolicyArns:
        - 'arn:aws:iam::aws:policy/service-role/AWSGlueServiceRole'
      Policies:
        - PolicyName: !Sub '${Env}-${DeploymentRootName}-${CompId}-role-policy-${AWS::AccountId}-${Region}'
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              -
                Effect: "Allow"
                Action: 
                  - "s3:*"
                  - "glue:*"
                  - "logs:*"
                  - "lakeformation:*"
                Resource:
                  - !Join [ '', ["arn:aws:s3:::*"]]
                  - !Join [ '', ["arn:aws:glue:*:*:", "*"]]
                  - !Join [ '', ["arn:aws:lakeformation:*:*", "*"]]
                  - !Join [ '', ["arn:aws:logs:*:*:", "*"]]
  RawToTransformedJobTrigger:
    Type: AWS::Glue::Trigger
    Properties:
      Name: !Sub "${Env}-${DeploymentRootName}-${CompId}-workflow-scheduled-trigger-${AWS::AccountId}-${Region}"
      WorkflowName: !Ref IngestionWorkflow
      Type: "SCHEDULED"
      Schedule: "cron(0/20 * ? * * *)" # Run every 10 minutes
      Description: "Triggers the data lake ingestion workflow."
      Actions:
        - JobName: !Ref RawToTransformedJob
          Arguments:
            "--job-bookmark-option": "job-bookmark-enable"
  RawToTransformedJob:
    Type: AWS::Glue::Job
    Properties:
      Name: !Sub "${Env}-${DeploymentRootName}-${CompId}-data-prep-job-${AWS::AccountId}-${Region}"
      Description: "Cleans raw data into the transformed bucket in prep for curation."
      MaxRetries: 3
      Role: !Ref GlueJobRole
      GlueVersion: "3.0"
      Command:
        Name: glueetl
        PythonVersion: "3"
        ScriptLocation: !Join ['', ["s3://", !ImportValue "LH:ResourceBucketName",  !Sub "/${AccountShorthand}-scripts/clean-data.py"]]
      ExecutionProperty:
        MaxConcurrentRuns: 2
      WorkerType: Standard
      NumberOfWorkers: 2
      DefaultArguments:  
        "--LOG_LEVEL": "INFO"
        "--enable-continuous-cloudwatch-log": true
        "--enable-continuous-log-filter": true
        "--enable-s3-parquet-optimized-committer": true
        "--enable-metrics": ""
        "--encryption-type": sse-s3
        "--job-bookmark-option": job-bookmark-enable
        "--TempDir": !Join ['', ['s3://', !ImportValue "LH:GlueTempBucketName", '/clean']]
        "--source_bucket_uri": !Join ['', ['s3://', !ImportValue "LH:RawZoneBucketName"]]
        "--target_bucket_uri": !Join ['', ['s3://', !ImportValue "LH:TransformedZoneBucketName"]]
  TransformedToCuratedJobTrigger:
    Type: AWS::Glue::Trigger
    Properties:
      Name: !Sub "${Env}-${DeploymentRootName}-${CompId}-data-curate-job-trigger-${AWS::AccountId}-${Region}"
      WorkflowName: !Ref IngestionWorkflow
      Type: "CONDITIONAL"
      StartOnCreation: true
      Description: "Initiates curation job under the condition that the data cleaning job runs successfully."
      Actions:
        - JobName: !Ref TransformedToCuratedJob
          Arguments:
            "--job-bookmark-option": "job-bookmark-enable"
      Predicate:
        Conditions:
          - LogicalOperator: EQUALS
            JobName: !Ref RawToTransformedJob
            State: SUCCEEDED
  TransformedToCuratedJob:
    Type: AWS::Glue::Job
    Properties:
      Name: !Sub "${Env}-${DeploymentRootName}-${CompId}-data-curate-job-${AWS::AccountId}-${Region}"
      Description: "Curates cleaned data into the target data lake bucket."
      MaxRetries: 3
      Role: !Ref GlueJobRole
      Command:
        Name: glueetl
        PythonVersion: "3"
        ScriptLocation: !Join ['', ["s3://", !ImportValue "LH:ResourceBucketName", !Sub "/${AccountShorthand}-scripts/curate-data.py"]]
      GlueVersion: "3.0"
      ExecutionProperty:
        MaxConcurrentRuns: 2
      WorkerType: Standard
      NumberOfWorkers: 2
      DefaultArguments:  
        "--LOG_LEVEL": "INFO"
        "--enable-continuous-cloudwatch-log": true
        "--enable-continuous-log-filter": true
        "--enable-s3-parquet-optimized-committer": true
        "--enable-metrics": ""
        "--encryption-type": sse-s3
        "--job-bookmark-option": job-bookmark-enable
        "--TempDir": !Join ['', ['s3://', !ImportValue "LH:GlueTempBucketName", '/curate']]
        "--source_bucket_uri": !Join ['', ['s3://', !ImportValue "LH:TransformedZoneBucketName"]]
        "--target_bucket_uri": !Join ['', ['s3://', !ImportValue "LH:CuratedZoneBucketName"]]
